# Text as Data: Analysis and Modeling

> Thursday, May 21th, 1:00pm - 3:00pm, CDIL Zoom.

## Objectives

- Critical understanding of text as data.
- Explore text analysis, machine learning, and visualization.

## Prep

- If you haven't already, **download and install [Visual Studio Code](https://code.visualstudio.com/)**

**Read the following:**
- Ted Underwood, ["Seven Ways Humanists are Using Computers to Understand Text"](https://tedunderwood.com/2015/06/04/seven-ways-humanists-are-using-computers-to-understand-text/) (2015). (intro overview of types of computational analysis)
- Matt Jockers, [The LDA Buffet is Now Open; or, Latent Dirichlet Allocation for English Majors](http://www.matthewjockers.net/2011/09/29/the-lda-buffet-is-now-open-or-latent-dirichlet-allocation-for-english-majors/) (Topic Modeling "Fable")

# Outline: 

## Text Analysis:

> To follow along see the [Text as Data](https://owikle.github.io/text-as-data/) workshop site

**Prepping your text**
- Finding and preparing text for analysis
- OCR and text cleaning

**Text Analysis**
- Word frequency and concordance with [Voyant Tools](https://voyant-tools.org/)
- Visualizing context with [WordTree](https://www.jasondavies.com/wordtree/)

## Machine Learning:

> To follow along see the [Topic Modeling](https://owikle.github.io/topicmodeling/) workshop site
- Topic Modeling in-browser with [jsLDA](https://mimno.infosci.cornell.edu/jsLDA/)

**Exploring big data**
- Google Books [Ngram Viewer](https://books.google.com/ngrams) (+ [how to use it](https://books.google.com/ngrams/info#))
    - Graphing composers: `Bach,Beethoven,Mozart,Corelli,Handel,Wagner`
- HathiTrust [Research Center Portal](https://sharc.hathitrust.org)

# Follow up Activity

**Do your own text mining**
Choose one of the tools we talked about today and spend some time exploring a text of your choice. 
Maybe you'd like to analyze your own writing, one of the corpora provided today, or a particular novel that you find on one of the text repository sites that we've talked about.

After you've finished exploring, reply to [this GitHub Issue](https://github.com/thecdil/mini-symposium/issues/3) with your thoughts on the following:
- What was your rationale for choosing the text analysis tool that you did?
- What judgment calls did you have to make (such as choosing stopwords, number of topics produced, scope of collection, etc.), and how did they affect your use of your results as evidence?
- Did you discover any insights? Limitations? Frustrations?

## Additional Readings

- Ted Underwood and Jordan Sellers, ["How Quickly Do Literary Standards Change?"](https://figshare.com/articles/How_Quickly_Do_Literary_Standards_Change_/1418394). 
    - Explicitly explains the text analysis research process, from collecting/selecting data to analysis. Published as a draft with more content, questions, and illustrations than are allowed in a traditional article. Also published traditionally as, Jordan Sellers and Ted Underwood, "The Longue DurÃ©e of Literary Prestige", MLQ 77:3 (2016). Additionally, a GitHub repository shares the code necessary to reproduce the analysis, [paceofchange](https://github.com/tedunderwood/paceofchange) (2015).
- [Cultural Analytics Now](http://post45.research.yale.edu/sections/contemporaries/cultural-analytics-now/), ed. Dan Sinykin, *post45* (2019).
    - A collection of articles critically evaluating the current state of quantitative methods in DH, particularly literary studies. First article is a review of Underwood's most recent book, *Distant Horizons*.

-----------------------

> Outlines: [0](day-0.md) | [1](day-1.md) | [2](day-2.md) | [3](day-3.md)
